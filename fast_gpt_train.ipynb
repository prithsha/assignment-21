{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from train_gpt2 import GPTConfig, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE UPDATE HERE\n",
    "max_lr = 6e-4 \n",
    "min_lr = max_lr * 0.1\n",
    "warmup_steps = 10\n",
    "max_steps = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 338025 tokens\n",
      "1 epoch = 20 batches\n",
      "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
      "using fused AdamW: True\n",
      "step0 | loss: 10.907730102539062 | dt: 4903.66ms | tok/sec:  3341.17 | norm: 6.90\n",
      "step1 | loss: 9.684803009033203 | dt: 3476.75ms | tok/sec:  4712.45 | norm: 5.48\n",
      "step2 | loss: 9.350849151611328 | dt: 16469.20ms | tok/sec:  994.83 | norm: 7.65\n",
      "step3 | loss: 9.317475318908691 | dt: 3371.88ms | tok/sec:  4859.01 | norm: 4.49\n",
      "step4 | loss: 8.831033706665039 | dt: 16368.21ms | tok/sec:  1000.96 | norm: 3.71\n",
      "step5 | loss: 8.676558494567871 | dt: 3444.75ms | tok/sec:  4756.22 | norm: 1.98\n",
      "step6 | loss: 8.497882843017578 | dt: 16698.80ms | tok/sec:  981.15 | norm: 2.15\n",
      "step7 | loss: 8.180829048156738 | dt: 3400.36ms | tok/sec:  4818.31 | norm: 2.47\n",
      "step8 | loss: 7.759794235229492 | dt: 16561.41ms | tok/sec:  989.29 | norm: 2.28\n",
      "step9 | loss: 7.447408676147461 | dt: 3436.88ms | tok/sec:  4767.12 | norm: 3.45\n",
      "step10 | loss: 7.022113800048828 | dt: 16615.98ms | tok/sec:  986.04 | norm: 1.47\n",
      "step11 | loss: 6.768238544464111 | dt: 3445.29ms | tok/sec:  4755.47 | norm: 1.15\n",
      "step12 | loss: 6.516155242919922 | dt: 16924.03ms | tok/sec:  968.09 | norm: 1.13\n",
      "step13 | loss: 6.670163631439209 | dt: 3443.44ms | tok/sec:  4758.03 | norm: 2.13\n",
      "step14 | loss: 6.626407623291016 | dt: 16786.50ms | tok/sec:  976.02 | norm: 0.87\n",
      "step15 | loss: 6.46325159072876 | dt: 3429.77ms | tok/sec:  4777.00 | norm: 0.72\n",
      "step16 | loss: 6.466886520385742 | dt: 16410.01ms | tok/sec:  998.42 | norm: 0.84\n",
      "step17 | loss: 6.4513750076293945 | dt: 3440.47ms | tok/sec:  4762.14 | norm: 0.74\n",
      "step18 | loss: 6.476830959320068 | dt: 16659.27ms | tok/sec:  983.48 | norm: 0.88\n",
      "step19 | loss: 6.332587718963623 | dt: 3444.42ms | tok/sec:  4756.67 | norm: 0.85\n"
     ]
    }
   ],
   "source": [
    "gpt_config = GPTConfig()\n",
    "\n",
    "gpt_config.B = 16\n",
    "\n",
    "train(warmup_steps=10,\n",
    "      max_steps=20,\n",
    "      min_lr=min_lr,\n",
    "      max_lr=max_lr, \n",
    "      gpt_config=gpt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"what services he has done for his country ?\"\n",
    "\n",
    "tokens = enc.encode(text)\n",
    "tokens = torch.tensor(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
